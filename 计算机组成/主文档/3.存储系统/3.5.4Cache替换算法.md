# Cache 替换算法详解

## 摘要

为解决 Cache 容量限制带来的块替换问题，本节系统解析四种主流替换算法。通过对比随机/FIFO/LRU/LFU 算法的实现机制与性能特征，揭示 LRU 算法在时间局部性支持与硬件实现复杂度间的平衡优势。

## 主题

Cache 替换策略的核心矛盾：空间效率与时间局部性维护。关键技术路径：计数器机制 → 访问模式追踪 → 替换决策优化。核心考察点：LRU 硬件实现、LFU 与局部性冲突、映射方式约束。

> 重点难点
>
> - LRU 计数器状态转移逻辑
> - LFU 的时间窗口失真问题
> - 组相联映射下的替换策略选择

## 线索区

### 知识点 1：替换算法基础框架

**定义**  
决定 Cache 满时被替换块的决策机制

> **约束条件**

- **全相联映射**：$N_{ways}=C_{cache}$，全自由度替换
- **组相联映射**：$N_{ways}=k$，组内替换
- **直接映射**：$N_{ways}=1$，无替换选择

**适用性矩阵**  

| 映射类型 | 需要替换算法? |
|------------|--------------|
| 全相联 | ✓ |
| 组相联 | ✓ |
| 直接映射 | ✗ |

### 知识点 2：算法核心对比

#### 2.1 随机替换(RAND)

- **原理**：均匀概率随机选择替换块
- **硬件成本**：**1 个**伪随机数发生器
- **缺陷**：可能替换热数据，命中率波动 ±**15%**

#### 2.2 先进先出(FIFO)

- **实现**：循环队列记录调入顺序
- **示例**：

  ```verilog
  always @(posedge clk)
    if (miss) replace_ptr <= (replace_ptr +1) % CACHE_SIZE;
  ```

- **Belady 异常**：增加 Cache 容量可能降低命中率

#### 2.3 最近最少使用(LRU)

**核心公式**  
$S_{LRU} = \arg\max_{b \in B}(t_{last\_access}(b))$

> **硬件实现**

- 每个 Cache 行维护**n 位**计数器（n=log₂N_ways）
- 状态转移：
  - 命中时：$C_{hit} ← 0$，其他$C_i = \begin{cases} C_i+1 & C_i < C_{hit} \\ C_i & \text{其他} \end{cases}$
  - 未命中：$C_{new} ← 0$，其他$C_i ← C_i+1$

**优势**  
严格遵循时间局部性，实测命中率比 FIFO 高**7-12%**

#### 2.4 最不经常使用(LFU)

**核心矛盾**  
访问频率 ≠ 时间局部性需求

**失效场景**：  
早期高频访问后长期闲置的块持续占用 Cache（需引入老化机制：$C_i ← \lfloor C_i/2 \rfloor$每 T 周期）

### 知识点 3：关键技术演进

```mermaid
graph LR
RAND-->FIFO(引入时间序)
FIFO-->LRU(精确时间戳)
LRU-->LFU(频率统计)
LFU-->ARC[自适应替换缓存]
```

## 总结区

**考点矩阵**  

| 算法 | 硬件成本 | Belady 异常 | 局部性支持 |
|------|--------|-----------|----------|
| RAND | 低 | 存在 | 无 |
| FIFO | 中 | 存在 | 弱 |  
| LRU | 高 | 不存在 | 强 |
| LFU | 极高 | 存在 | 中等 |

> **设计权衡要点**

1. LRU 实现成本随相联度指数增长（n-way 需 n log n 位）
2. 现代处理器多采用**伪 LRU**（树形近似算法）降低硬件开销
3. 写入策略（write-back/through）会同步影响替换决策

需要补充任何细节或调整表达方式请随时告知。
